<!DOCTYPE html><html><head>
    <meta charset="utf-8">
    <title>Exploraciones digitales para humanistas</title>
    
    <link rel="stylesheet" href="assets/html.css">

  </head>
  <body data-type="book">
    <header class="topheader">
      <hgroup class="mainh">
        <h1>Exploraciones digitales para humanistas</h1>
        <h2>---subtítulo----</h2>
      </hgroup>
      <ul class="titlebar1">
        <li><a>*</a></li>
        <li><a>**</a></li>
      </ul>
    </header>
    <section class="mainset">
      <aside class="sidebar">
        <nav data-type='toc'>
  <h1>Contenido</h1>
  <ol>
<li>
    <a data-toc="chapter" href="informacion.html#informacion-QLMvfkW">Información</a>
    <ul>
<li>
    <a data-toc="sect1" href="informacion.html#introduccion-0WaqfrW">Introducción</a>
  </li>
<li>
    <a data-toc="sect1" href="informacion.html#la-primera-diferencia-Oomnf74">La primera diferencia</a>
  </li>
<li>
    <a data-toc="sect1" href="informacion.html#la-segunda-diferencia-vLNdfno">La segunda diferencia</a>
  </li>
<li>
    <a data-toc="sect1" href="informacion.html#conclusiones-DLYwf7o">Conclusiones</a>
  </li>
  </ul>
</li>
  </ol>
</nav>
      </aside>
      <article class="chapter">
        <section data-type="chapter" id="informacion-QLMvfkW">
  <header class="chapter-headers">
    <h1>Información</h1>
    <h2>Diferencias que hacen diferencias</h2>
  </header>

  <section data-type="sect1" id="introduccion-0WaqfrW">
    <h1>Introducción</h1>
    <p class="text-p">
      En la vida contemporánea se habla constantemente de información, prinicipalmente en los medios de comunicación y en el rápido movimiento del mundo digital. Información es un término que tiene un uso cotidiano, intuitivo, que todas las personas entendemos, relacionado con el conocimiento que nos permite llevar a cabo las tareas de la vida diaria, pero también tiene ciertas conotaciones técnicas y tecnológicas, que tienen que ver con infraestructuras de telecomunicaciones y con datos registrados en grandes computadores, cuya operación está oculta para la mayoría de la gente. Este capítulo aborda los dos sentidos del concepto, sus relaciones estrechas, y la importancia que tiene para las humanidades considerar los imbricamientos entre la información y el significado.
    </p>
    <p class="text-p">
      Como punto de partida tomemos una definición concreta pero muy fructífera de información: el ciberantropólogo Gregory Bateson decía que la información consiste en <mark>"una diferencia que hace una diferencia"</mark> <span data-type="footnote"><a href="#fn1">1</a></span>. Aunque aquella es una frase ya famosa en los círculos especializados de la cibernética, su poderoso mensaje es críptico a primera vista. ¿Qué quiso decir Bateson con esta definición? Para desempaquetarla un poco, podríamos decir que la primera diferencia en la frase se refiere a la información formalmente definida, domesticada, a sus operaciones matemáticas, clasificadas sintácticamente, útiles para la ingeniería de la comunicación y la computación. La segunda diferencia se refiere al significado, al contenido semántico y al uso pragmático, a la utilidad que tiene la información para una persona —o para cualquier ser vivo—, al nuevo conocimiento adquirido, al aprendizaje que sirve para acciones futuras. La primera diferencia <mark>es</mark> una diferencia, pues está pasivamente registrada en un sustrato físico, mientras que la segunda <mark>hace</mark> una diferencia, pues implica moverse activamente en el mundo basado en la lectura del sustrato que contiene el registro. Para que exista información en el sentido de Bateson, necesitamos de las dos diferencias. Aunque distintas teorías las separen y las consideren aisladamente son, en realidad, para recontextualizar una frase Batesoniana, una unidad necesaria.
    </p>
    <p class="text-p">
      Entonces, en este capítulo aprovecharemos la frase para hacer una lectura semiotécnica del concepto de información. Es decir, veremos cómo existen procedimientos, teorías y reglas que regulan y configuran los aspectos materiales, las prestaciones y la manipulación de la información como objeto concreto —la primera diferencia—, y también veremos cómo esos aspectos técnicos se relacionan con los problemas del significado y la interpretación, cómo se conectan con el uso concreto que le dan las personas a lo que perciben como información —la segunda diferencia—. Tal lectura semiotécnica servirá a su vez como un fundamento para entender reflexivamente el impacto que puede tener el uso del concepto de información para las humanidades: ¿qué sucede cuando se tratan los fenómenos y los objetos culturales como información?, ¿es posible codificarlos en su totalidad?, ¿qué límites plantea el lado técnico de la información?, ¿qué problemas plantea lo informacional a lo humanístico?, ¿qué requiere una teoría de la información que tenga verdaramente en cuenta al significado?
    </p>
  </section>

  <section data-type="sect1" id="la-primera-diferencia-Oomnf74">
    <h1>La primera diferencia</h1>
    <h2>La teoría matemática</h2>

    <p class="text-p">
      En su descripción más formal y matemática, la información <mark>es</mark> la cantidad de diferencias que puede contener un mensaje codificado en un soporte o canal. Un canal es cualquier medio material que pueda ser modificado físicamente y con el que se puedan registrar diferencias: desde un pedazo de papel hasta una compleja red de fibra óptica. Esta idea se la debemos a Claude Shannon, el inventor de la <mark>teoría matemática de la información</mark>, y a Warren Weaver, quien colaboró con una interpretación importante de la teoría <span data-type="footnote"><a href="#fn2">2</a></span>. Por ejemplo, un interruptor, de los que usamos para prender y apagar la luz, es un soporte que contiene dos estados posibles: encendido o apagado. Es decir, contiene una sola diferencia; pues para diferir se necesitan dos, como mínimo. La unidad de medida de las diferencias en información es el bit, un término que se ha hecho cada vez más común en nuestra vida gracias al uso extendido de los computadores digitales. Concretamente, bit quiere decir binary unit, o sea, unidad binaria, porque guarda la diferencia entre dos opciones, la cantidad mínima posible de diferencias. Pero también, si lo vemos así, quiere decir "pedacito", en inglés. Un bit es el pedacito más pequeño de la información. Así, si codificamos la información del interruptor en cuestión en un sistema binario más abstracto, podemos decir que 0 es apagado y 1 es encendido.
    </p>

    <div class="p5-wrapper"><p>El interruptor contiene un bit de información (dos diferencias)</p><iframe src="https://srsergiorodriguez.github.io/exploraciones-sketches/C1/1interrupt/" width="650px" height="130px" frameborder="0" allowfullscreen=""></iframe></div>

    <p class="text-p">
      Para Shannon, y la posterior interpretación de Weaver, el espacio que debemos tener disponible en un soporte o un canal en el que queremos guardar información depende de la cantidad de "sorpresa", o el número de posibilidades que podemos esperar que represente el soporte. Un interruptor puede estar solamente en una de dos opciones, así que solo necesitamos un bit. Pero si quisiéramos registrar una letra, de las 27 que hay en el alfabeto del español, tendríamos que usar la famosa fórmula de Shannon que sirve para determinar el número de bits necesarios:
    </p>

    <p class="text-p formula">
      H = log<sub>2</sub>(k)
    </p>

    <p class="text-p">
      Donde H es el número de bits y k es el número de posibles diferencias que queremos poder guardar en el soporte o mover en el canal, suponiendo que todas las letras tienen el mismo chance de aparecer. Entonces, necesitamos como mínimo 4.7548 bits en el soporte para guardar una letra. Como en los sistemas digitales realmente los bits son las unidades más pequeñas, y por eso son indivisibles, en realidad necesitaríamos 5 bits —nos sobraría un poco—. Y para codificar cada letra usaríamos una secuencia binaria de esos 5 bits. Digamos, 00000 para la A, 00001 para la B, 00010 para la C, 00011 para la D, y así sucesivamente.
    </p>

    <div class="p5-wrapper"><p>Aquí, combinaciones de bits corresponden con letras del alfabeto</p><iframe src="https://srsergiorodriguez.github.io/exploraciones-sketches/C1/2bits/" width="650px" height="100px" frameborder="0" allowfullscreen=""></iframe></div>

    <h2>El encerramiento del significado</h2>

    <p class="text-p">
      Como afirman Gane y Beer <span data-type="footnote"><a href="#fn3">3</a></span>, Shannon y Weaver, con su Teoría matemática de la información, concebían tres niveles o problemas de la información: el <mark>nivel A</mark> —el que a Shannon y a Weaver realmente les interesaba— consiste en cómo se pueden transmitir mensajes con precisión a través de un canal. Por eso buscaban una manera estricta de definir la capacidad en bits que debe tener el canal para que se pueda enviar el mensaje por medio de señales físicas concretas, y además buscaban lidiar con problemas como el ruido que puede distorsionar la señal y producir un mensaje erróneo. El <mark>nivel B</mark> consiste en cómo se puede codificar y decodificar un mensaje efectivamente —por ejemplo, cómo volvemos de 00011 a la letra D—, así que ese es un problema que corresponde a los conceptos de <a>código y función</a>, que tienen su propio capítulo. El <mark>nivel C</mark> consiste en cómo una u otra información efectivamente afecta la conducta, y está más en conexión con lo que podemos llamar "significado"; que discutiremos en mucho más detalle más adelante.
    </p>

    <p class="text-p">
      El interés particular de Shannon por el nivel A se debe a que él trabajó varios años de su vida en los Laboratorios Bell, un centro de investigación de la más grande compañía de teléfonos en Estados Unidos durante buena parte del siglo XX. Para los <i>Bell Labs</i>, el problema de medir la cantidad de información que podía ser enviada por los cables teléfonicos era central, pero no tenía ninguna importancia el contenido y el sentido de los mensajes que se enviaban, pues esos pertenecían a las vidas privadas de las personas. Así, la invención o descubrimiento teórico de Shannon estableció un sistema con el que es posible aislar efectivamente los niveles, y así permitió que la ingeniería de la información y la comunicación se preocupara solo por la infraestructura de almacenamiento, transporte y manipulación formal de la información, sin tener que pensar nunca en su significado. En otras palabras, se separó a la primera diferencia de la segunda. Un telegrama, una llamada telefónica, un e-mail, da igual, pues todo mensaje se puede, en apariencia, medir en bits.
    </p>

    <p class="text-p">
      Es por esto que Paul Kockelman dice que la información, en el sentido de la primera diferencia, es el encerramiento —el <i>enclosure</i>— del significado <span data-type="footnote"><a href="#fn4">4</a></span>: es la construcción de un sistema formal con el que se puede domesticar el registro de diferencias de una manera en la que sean fácilmente traducibles, a través de códigos, a muchos medios diferentes. Sin embargo, sobre esto, Kockelman[5] advierte que realmente "ser aplicable a muchos mensajes no significa tanto que tal medio está preparado especialmente para los contenidos de cualquier dominio que pudiera encontrarse, sino más bien que tiene la capacidad de asimilar esos contenidos para sí mismo, o acomodarse a sí mismo a esos contenidos sobre la marcha o después del hecho" <span data-type="footnote"><a href="#fn5">5</a></span>. En otras palabras, el medio tecnológico de la información, junto con la formalización del código binario, es un sistema simbólico que hemos creado artificialmente para traducir todas las cosas a un solo lenguaje: el lenguaje de las diferencias discretas. Es decir, diferencias claramente demarcadas entre sí, diferencias digitales. Los objetos digitales,  con su capacidad extendida de representar muchos dominios diferentes son lo que Bowker y Star llamarían <i>objetos límites</i>, es decir: “esos objetos que a la vez habitan varias comunidades de práctica y satisfacen los requerimientos informacionales de cada una de ellas” <span data-type="footnote"><a href="#fn6">6</a></span>. Aunque, como afirma Kockelman, tal objeto límite no necesariamente es el más natural ni el más perfecto, es solo sumamente conveniente por su eficiencia. No obstante, esta eficiencia no debería ser confundida con la idea de que, muy en el fondo, todas las cosas se pueden reducir a diferencias binarias, como discutiremos más adelante.
    </p>

    <h2>El metamedio</h2>

    <p class="text-p">
      Alan Kay y Adele Goldberg, quienes fueron figuras muy importantes en el desarrollo de una gran cantidad de principios computacionales que usamos hoy en día, afirmaban en su ensayo <i>Personal Dynamic Media</i> <span data-type="footnote"><a href="#fn7">7</a></span> que lo digital constituye un metamedio, pues, a través de la relación entre la codificación en información universalizada y los distintos sistemas periféricos de decodificación computacional —pantallas y parlantes, por ejemplo— se pueden imitar todos los otros medios: el cine, la radio, el sonido, la fotografía, el libro, etc. Kay y Golberg hacían sus afirmaciones a finales de los setentas, y hoy, en nuestro tiempo, esa idea es aún más evidente. Lev Manovich ha ampliado la idea del metamedio en su libro <i>Software takes command</i> <span data-type="footnote"><a href="#fn8">8</a></span> y la ha anclado a su propia versión de lo que en computación llaman una <i>Estructura de datos</i>, es decir, un sistema en el que se optimiza el acceso, manipulación, e inventario de un agregado de información por medio de una arquitectura de disposición de los datos. Aunque hay un capítulo dedicado a este tema, a la luz de lo que hemos recorrido hasta ahora podríamos decir que para Manovich la estructura de datos es una selección organizada para la representación de datos en conjunto. Dependiendo de la estructura de datos que se use para imitar algún medio previo desde el metamedio de lo digital, habrá implicaciones diferentes en cómo entenderemos medio imitado. De hecho, como lo ve Manovich, el metamedio digital imita pero también hibridiza y extiende los medios tradicionales con prestaciones que en su forma original eran imposibiles. Es decir, le añade dimensiones a la estructura de datos; de ahí que Manovich hable de <i>nuevos medios</i> cuando se refiere a los medios digitales como el software y las plataformas de internet.
    </p>

    <figure class="illustration right">
      <figcaption>Ivan Sutherland, uno de los primeros investigadores de la interacción humano-máquina junto a su interfaz <i>sketchpad</i>, que imita y extiende el medio del cuaderno de dibujos (<a href="https://commons.wikimedia.org/wiki/Category:Ivan_Sutherland#/media/File:SketchpadDissertation-Fig1-2.tif" target="_blank">Fuente</a>, CC BY-SA 3.0)</figcaption>
      <img alt="Ivan Sutherland y Sketchpad" src="assets/sutherland.jpg">
    </figure>

    <p class="text-p">
      Hoy en día todos los medios han venido siendo reemplazados por sus sucedáneos digitales; pensemos, por ejemplo, en la fotografía análoga y los filtros de Instagram, o en el gramófono y la aplicación <i>Spotify</i>. Sobre esto, Kittler diría que "la digitalización general de los canales de información borra las diferencias entre los medios individuales [...] Dentro de los computadores todo se convierte en un número: cantidad sin imagen, sonido o voz" <span data-type="footnote"><a href="#fn9">9</a></span>. Sin embargo, para Manovich, aunque en el fondo todo sea un número, en la interfaz, por el contrario, todos los medios imitados tienen un nuevo aire; la edición de video puede ser también una composición de collage, el texto puede ser <i>motion graphics</i> o una red de hipervínculos, el sonido puede tener una continuidad eterna, la realidad puede aumentarse o hacerse virtual. En fin, el medio se expande de formas en las que mantiene ciertas conexiones con lo viejo y nuevas oportunidades de interacción y sentido. Dicho esto, se hace claro que las implicaciones del metamedio son importantes: aunque el medio se expande, porque permite una fácil comunicación entre medios imitados a través del lenguaje común del binario, el efecto de encerramiento y de que todo es posible con lo digital se acrecienta. En cierta manera los demás medios se presentan como inecesarios, porque, en apariencia son reemplazables por un computador. Sin embargo, esta idea puede ser ilusoria, y siempre es necesario preguntarse qué se esta dejando de lado. En otras palabras, con la expansión que permite el metamedio, también viene una reducción en cuanto a las particularidades no-codificables de los otros medios. Pensemos, por ejemplo, en la fotografía análoga y la digital. Aunque en apariencia ambos sistemas tienen los mismos efectos para nuestra percepción, una foto digital se ve limitada por la cantidad de bits que codifican su resolución y la cantidad de otro tipo de información que puede contener: los rangos de color, el tamaño, el formato de codificación, etc. Una foto análoga, por su parte, no tiene en principio esos limitantes, porque es una representación indexica y precisa, lograda en un sustrato por medios químicos y por el contacto de la luz. Una foto análoga no se pixela, porque no está compuesta por esas pequeñas unidades discretas informacionales llamadas pixels. Así es, en teoría, infinitamente ampliable, infinitamente gradual —aunque, dependiendo del lente, el enfoque y la calidad del revelado esa ampliación sea difusa—. Por otra parte, la fotografía digital contiene otra información que no está contenida en el sustrato análogo, tiene metadatos, es decir, información paralela acerca de su producción y sus especificaciones técnicas.
    </p>

    <h2>Un lenguaje universal</h2>

    <p class="text-p">
      Umberto Eco, en su libro <i>The search for the perfect language</i> <span data-type="footnote"><a href="#fn10">10</a></span>, hace un recuento histórico de los intentos humanos por crear lenguajes universales. Es decir, lenguajes que permitan referirse a todas las cosas de formas sistemáticas y organizadas y, en consecuencia, que establezcan un sistema ideal con el que todas las personas podríamos comunicarnos. Como lo demuestra Eco, tal intención universalizante no surge con las teorías de la información, pues existen innumerables ejemplos a lo largo de la historia: el Latín en contraposición a las lenguas vernáculas, la interpretación de las categorías Aristotélicas en el árbol de Porfirio, el <i>Ars Magna de Ramón Llull</i>, el <i>Real Character</i> de John Wilkins —hecho famoso por un cuento de Jorge Luis Borges—, el Lenguaje del pensamiento de Gottfried Leibniz, el Esperanto, entre otros. Parece que el mito de la torre de Babel pesa sobre las conciencias humanas. Sin embargo, solo el bit de la teoría matemática de la información ha logrado producir de forma extendida ese efecto de encerramiento que define Kockelman. Con la invención de la computación, este lenguaje se ha hecho cada vez más ubicuo, pues los sistemas digitales se comunican y operan sobre información de diferencias discretas y, como lo definía Shannon, no necesitan nunca preocuparse por lo que significan los agregados de unos y ceros. Así, con el crecimiento expandido de la computación en nuestras vidas cotidianas, hemos terminado por acostumbrarnos a la idea de que, efectivamente, todo puede ser medido en bits, bytes, kilobytes, megabytes y gigabytes.
    </p>

    <figure class="illustration left">
      <figcaption>Esta imagen, por Guamán Poma, representa dos formas de registro de información Inca: el Quipú, un sistema de sogas con el que se podían registrar números y otros datos por medio de nudos, y la Yupana, una especie de ábaco con el que se pueden hacer operaciones aritméticas (<a href="https://commons.wikimedia.org/wiki/Category:Ivan_Sutherland#/media/File:SketchpadDissertation-Fig1-2.tif" target="_blank">Fuente</a>, Dominio público)</figcaption>
      <img alt="Quipu y Yupana" src="assets/quipu.png">
    </figure>

    <p class="text-p">
      
      Sin embargo, aquí podemos cuestionarnos si efectivamente la información digital es capaz de codificar cualquier mensaje, o si, por la ambición de tener un lenguaje universal, estamos dejando de lado detalles importantes que después asumimos como inexistentes porque no caben dentro de la posibilidad expresiva del código binario. El propio Eco se pregunta esto en el libro <i>La estructura ausente</i> <span data-type="footnote"><a href="#fn11">11</a></span>, y hace referencia a lo que él llama <mark>rasgos suprasegmentales</mark>, es decir, características del lenguaje que afectan a varios segmentos del habla: los acentos, la entonación, el tono, etc. y a los <mark>rasgos facultativos</mark>, es decir, elementos estilísticos de un signo que tienen que ver con la personalidad de quien los produce, más que con un sentido intencional. Los rasgos suprasegmentales y los facultativos son las marcas que dejan las personas a su paso cuando crean signos. Para Eco, ambos tipos de rasgos son difíciles de codificar por sus cualidades continuas, expresivas y difícilmente diferenciables. Son, por decirlo de alguna manera, códigos débiles que escapan a la formalización estricta.
    </p>

    <p class="text-p">
      Algo similar dice Frederich Kittler en <i>Gramophone, film, typewriter</i> <span data-type="footnote"><a href="#fn12">12</a></span>. Los medios análogos de la escritura manual, el fonógrafo, el gramófono y el cine logran captar rasgos que se pierden en los lenguajes simbólicos de la imprenta, la máquina de escribir y los computadores digitales. Con lo digital, todas las letras del alfabeto se estandarizan, todo se reduce a categorías genéricas manejables, a diferencias bien definidas. Mientras que con nuestro acento podemos decir una "A" que se parece a una "O", con el computador, en cambio, el sistema no nos lo permite. Recordemos que uno de los principios fundamentales de la teoría matemática de la información está en establecer un conjunto de valores que cubren toda posibilidad de sorpresa. Para Kittler, el computador es una síntesis de la máquina de escribir, exenta de elementos sobrantes: "la máquina de escribir de [Cristopher] Shole reducida a su principio fundamental nos ha respaldado hasta el día de hoy. [Alan] Turing simplemente se deshizo de la gente y las mecanógrafas que Remington e hijo necesitaban para leer y escribir" <span data-type="footnote"><a href="#fn13">13</a></span>. En otras palabras, el principio digital computacional es muy similar a una estructura tipográfica: se define un grupo de caracteres y de operaciones con las que se manipulan los caracteres, se reorganizan y se diagraman, pero nada puede representarse si no se concibió en un principio como una opción posible dentro del sistema.
    </p>

    <figure class="illustration whole">
      <figcaption>La tipografía digital homogeneiza las cualidades facultativas subjetivas</figcaption>
      <img alt="Escritura" src="assets/escritura.jpg">
    </figure>

    <p class="text-p">
      Para las humanidades esta limitación expresiva tiene un impacto importante. Los objetos y fenómenos de la cultura humana no necesariamente se pueden reducir a diferencias binarias. Por ejemplo, como lo aseguran Brown y Duguid <span data-type="footnote"><a href="#fn14">14</a></span> una página manuscrita contiene cualidades que no se reducen a la combinación de letras que conforman las palabras: existen condiciones de deterioro del papel, anotaciones en las márgenes, subrayados, dibujos, cambios facultativos en la escritura, incluso olores, etc. que las hacen especiales. Todas estas particularidades son extremadamente difíciles de codificar. Por su propia naturaleza se escapan a la clasificación estricta porque están, por así decirlo, llenas de sorpresas, de modulaciones infinitas. Una aproximación humanista a lo digital no puede perder de vista esta situación, pues caería en la idea incorrecta de que solo lo que es codificable es valioso, manejable y estudiable. Aún más, cabría preguntarse si la adopción de lo digital tiene efectos sobre lo que entendemos por lo humano, lo que Bowker y Star <span data-type="footnote"><a href="#fn15">15</a></span> llaman torque o torsión: la fuerza que ejercen los sistemas de clasificación sobre las vidas de las personas. Es decir, si la idea de lo discreto y claramente diferenciable se usa como marco de entendimiento para entendernos a notrosos mismos. Por ejemplo, en el caso de la identidad, el binarismo oculta el gradiente de posibilidades que existe entre un extremo y otro: “las biografías y las categorías están a lo largo de trayectorias que entran en conflicto. Las vidas son retorcidas, incluso rotas, en un intento de forzar una dentro de la otra. Esas torciones pueden ser pequeñas o grandes, pero son una manera de entender la co-construcción de las vidas y sus categorías” <span data-type="footnote"><a href="#fn16">16</a></span>. Como afirma Yanni Alexander Loukissas <span data-type="footnote"><a href="#fn17">17</a></span>, a pesar de su pretensión universal, todos los datos son locales, así como su registro informacional, y deben ser entendidos desde tal localidad. Es decir, deben situarse en contextos y circunstancias específicas, y deben hacerse explícitas las subjetividades que los conceptualizan y los registran. La supuesta universalidad de la información oculta grandes asimetrías con respecto a su acceso y su interpretación: grupos particulares en contextos concretos han desarrollado sus teorías, han construido sus infraestructuras y han controlado el contenido de sus mensajes. La información como medio universalizante oculta que para registrar y procesar información se necesitan recursos, y que esos recursos no están disponibles para todos.
    </p>

    <figure class="illustration whole">
      <figcaption>Caída de la Torre de Babel, por Cornelis Anthonisz (<a href="https://www.rijksmuseum.nl/en/collection/RP-P-1878-A-1641" target="_blank">Fuente</a>, Dominio público)</figcaption>
      <img alt="Torre de babel" src="assets/babel.jpg">
    </figure>

    <h2>La finca raíz de la información</h2>

    <p class="text-p">
      El teórico Donald MacKay, especialmente en su libro <i>Information: mechanism and meaning</i> <span data-type="footnote"><a href="#fn18">18</a></span> concebía tres tipos diferentes de contenidos-informacionales que le dan forma a la información: el <mark>contenido seleccional</mark> —que es equivalente a la medida de diferencia propuesta por Shannon—, el <mark>contenido estructural</mark> y el <mark>contenido métrico</mark>. Aunque con otro nombre, ya desarrollamos la idea del contenido seleccional, ahora merece la pena ahondar ahora en los otros dos tipos de contenidos-informacionales. Las formas de contenido-informacional se ubican aún en el nivel A de los problemas de la información, pero ofrecen ciertos matices sería importante mencionar, porque nos darán herramientas críticas para entender las imbricaciones entre el sustrato y el sentido de forma más compleja.
    </p>

    <p class="text-p">
      El contenido estructural se relaciona con lo que Kockelman <span data-type="footnote"><a href="#fn19">19</a></span> llama un <i>marco de relevancia</i>. Es decir, la cantidad de dimensiones que usamos para representar algo en términos de información. Recordemos el ejemplo de codificar caracteres: habíamos dicho que necesitaríamos 5 bits para codificar las 27 letras del español, pero, si añadiéramos otra dimensión, o sea, si ampliáramos el marco de relevancia, necesitaríamos más bits. Una dimensión puede entenderse como un grupo coherente de cualidades que pueden usarse para describir un objeto; cada nueva dimensión añadida proporciona más detalles y más complejidad. Por ejemplo, si quisiéramos diferenciar entre mayúsculas o minúsculas necesitaríamos al menos 6 bits, un bit más. Pues ahora, además de la lista de 27 letras, tenemos un nuevo set de cualidades: tales letras pueden ser mayúsculas o minúsculas. El propio Gregory Bateson tenía un término para este tipo de contenido: <i>tipado lógico</i> —<i>logical typing</i>, en inglés—: la escogencia de una forma particular de pensamiento para entender el mundo, en contraposición a otras formas posibles <span data-type="footnote"><a href="#fn20">20</a></span>. El tipado lógico ofrece una especie de fundamento para el pensamiento, lo que Bateson llamaba una tautología. Es decir, un andamiaje en principio arbitrario sobre el que se pueden construir nuevas elaboraciones más complejas, una serie de decisiones que construyen las reglas de un mundo epistémico. En nuestro ejemplo anterior, una tautología sería la posibilidad de las letras de ser mayúsculas o minúsculas, y otra sería la diferencia que ofrece cada una en el alfabeto. Una elaboración compleja sería la combinación de una letra escogida con la selección de si es mayúscula o minúscula: A, a, B, b. Así, a partir de la combinación de tautologías se obtienen múltiples resultados consistentes con los principios básicos del andamiaje.
    </p>

    <p class="text-p">
      El contenido estructural es un concepto clave para los humanistas que buscan trabajar con lo digital, porque direcciona el pensamiento a la cuestión de qué es lo que se quiere representar, qué se quiere obtener con la representación y qué dimensiones son entonces necesarias para lograr el objetivo. Por ejemplo, si queremos codificar un texto complejo, ¿qué elegimos?, ¿las palabras?, ¿las formas manuscritas?, ¿los colores?, ¿la disposición en la página?, ¿el ritmo de la escritura?. Visto de otra forma, el contenido estructural es la teoría, el punto de vista o el instrumento que usamos para definir la diferenciación que registraremos como información. Podemos pensar el contenido estructural como una forma de aliviar el problema de la representación discreta: aunque no podemos introducir infinitas distinciones, sí podemos ampliar el número de dimensiones para captar mejor el objeto de estudio.
    </p>

    <p class="text-p">
      El contenido métrico, por su parte, corresponde al grado de resolución o de granularidad escogido para representar algo como información. Por ejemplo, yo podría indicar mi ubicación con una precisión de metros, centímetros o milímetros. El contenido métrico se relaciona entonces con los estándares y sistemas de valoración, en el sentido en que requieren definir una calidad esperada, un umbral dentro del cual algo tiene un detalle descriptivo aceptable, y para lograrlo es necesario crear un sistema de medida que permita dar cuenta de esa calidad. A este respecto además hay que añadir que, si se busca más resolución, puede esperarse la necesidad de tener más capacidad de almacenamiento en bits, como es común con los archivos de fotos o de música en nuestros computadores: una canción en formato mp3, que está comprimida, tiene menos contenido métrico que la misma canción en formato WAV, que no tiene compresión.
    </p>

    <div class="p5-wrapper"><p>Prueba seleccionando distintos niveles de detalle o profundidad de bits con el deslizador, luego presiona el triángulo para reproducir el sonido</p><iframe src="https://srsergiorodriguez.github.io/exploraciones-sketches/C1/3depth/" width="650px" height="180px" frameborder="0" allowfullscreen=""></iframe></div>

    <p class="text-p">
      No obstantes las críticas que hemos hecho a la información como medida de diferencia, lo digital y su consecuente desarrollo técnico y tecnológico ha traido consigo la capacidad increíble —aunque ya nos hayamos acostrumbrado a ella— de comunicarnos a distancia y de mantener registros de mensajes durante periodos muy largos de tiempo, aunque no eternos. Esta no es una capacidad menor, y basta con pensar en los límites de la transmisión de la comunicación hace unas décadas para notar el rápido cambio técnico que cada vez se acelera más. Sigfried Zielinski en <i>Arqueología de los medios</i> <span data-type="footnote"><a href="#fn21">21</a></span>, por ejemplo, da cuenta de los complejos, creativos y muchas veces tortuosos caminos que ha tomado la humanidad para crear formas de comunicación relativamente eficientes. Desde el voz a voz de los mensajeros Chasquis en el Imperio Inca hasta los agnósticos bits de nuestros días, el problema siempre ha sido el mismo: poder registrar y luego llevar un mensaje de un lugar a otro. Sin embargo, como lo vería Zielinski, es más interesante la historia anecdótica de las búsquedas vanas, los fracasos y las victorias paradójicas que los éxitos absolutos, pues nos permiten ver con más claridad el esfuerzo y las complejidades que damos por sentado cuando podemos, con solo unos tecleos, transportar información de un lugar a otro. Estos fallos y desaciertos en la infraestructura hacen ver más claramente que al final, la información no es un éter intangible sino un objeto que depende estrictamente de un sustento material. 
    </p>

    <p class="text-p">
      Dicho todo lo anterior podemos ver que el contenido estructural y el contenido métrico definen necesariamante la cantidad de contenido seleccional —el número de bits que se requieren para registrar información—: entre más dimensiones en un marco de relevancia, más bits; entre más resolución, más bits también. Aquí nos encontramos con una encrucijada económica: para poder describir mejor un objeto podemos ampliar su contenido estructural y métrico, pero eso implica mayores costos en el sutrato que finalmente representará la información. En su aspecto técnico, la información cuesta espacio, dinero, trabajo y tiempo, así que los recursos que se disponen para manipularla no pueden ser infinitos. De hecho, como afirma Jussi Parikka en <i>A geology of media</i> <span data-type="footnote"><a href="#fn22">22</a></span>, existe una geología y una ecología de los medios que normalmente está oculta a nuestros ojos: en algún lugar, las letras que componen estas palabras, están siendo procesadas por un servidor que las almacena y las distribuye a quien las busque y quiera leerlas. Mantener ese servidor funcionando conlleva ciertos requerimientos infraestructurales y de energía; no es gratis guardar información. Es así que para los humanistas aparece una decisión importante: qué registrar dentro de los límites de lo representable digitalmente y qué no, qué es suficiente y qué es innecesario, qué costos se deben asumir. En latinoamérica esto es particularmente crítico, pues, como dijimos antes, las infraestructuras tecnológicas son asimétricas, y nuestro contexto carece de muchas de ellas. Como afirmaría Domenico Fiormonte <span data-type="footnote"><a href="#fn23">23</a></span>, Latinoamérica se encuentra en las márgenes de la producción tecnológica, en una circunstancia paradójica en la que a la vez es consumidora de un conocimiento global pero juega menor parte en su teorización y producción. En ese sentido, la forma local como tratamos con la información parte de una relación subordinada con quienes son dueños de tales infraestructuras. Recordemos que, por ejemplo, la teoría matemática de la información surgió de un gran centro de investigación tecnológico estadounidense, los Bell Labs. Para nosotros, existen mayores limitaciones presupuestales, debido a la carencia de infraestructuras e inversión, y eso quiere decir que las decisiones con respecto a la estructura y la métrica son aún más relevantes. Tal vez, unas humanidades digitales en Latinoamérica deben ser más recursivas y más creativas con los usos de la información, y deben, a pesar de las limitaciones, crear tipados lógicos fructíferos que permitan crear formas alternativas de entender la cultura desde nuestro propio lugar subordinado y precario; alternativas que correspondan con nuestras formas locales de entender y crear información.
    </p>

    <p class="text-p">
      Vista así, la anterior diferenciación de los tres tipos de contenidos-informacionales ayuda a complejizar aún más el concepto de información, a enriquecerlo —¿a darle más contenido estructural y métrico?—, y a darle un valor fundamental en nuestro contexto. Una idea interesante que surge de esta concepción de la información es la implicación que tiene escoger distintos contenidos estructurales, marcos de relevancia, tipados lógicos, teorías, o epistemes: dependiendo del marco, nuevos secretos se revelan (para usar las palabras de Kockelman <span data-type="footnote"><a href="#fn24">24</a></span>). Un ejemplo concreto de tal implicación puede verse con la diferencia clara que se evidencia entre usar coordenadas cartesianas o cordenadas polares para hacer gráficos por computador —en términos manuales podríamos compararlo con el contraste entre la regla y el compás—. Con uno u otro de los sistemas de coordenadas se pueden ubicar puntos en el espacio y construir todo tipo de formas, pero el primer sistema hacen más fácil hacer líneas, mientras que el segundo es ideal para hacer círculos. Cristalizar marcos de relevancia únicos puede resultar inconveniente para comunicar un mensaje o para interpretarlo, pues ciertas formas de representar la información se reduce a ciertas formas de pensar o de encapsular el mundo. Pero, debido a la economía de la información, no es posible escoger todas las formas, siempre es necesario tomar una decisión. Ante la precariedad, es crítico definir el tipado lógico que se quiere usar para representar lo humano, y ante la subordinación, es crítico que ese tipado lógico no dependa fundamentalmente de una relación asimétrica.
    </p>
    
    <div class="p5-wrapper"><p>Dos formas diferentes de describir la posición: coordenadas cartesianas o coordenadas polares. Cada tipo de coordenadas ofrece un tipado lógico con el que es más fácil describir ciertas figuras: líneas rectas o circulares, respectivamente</p><iframe src="https://srsergiorodriguez.github.io/exploraciones-sketches/C1/4coor/" width="650px" height="365px" frameborder="0" allowfullscreen=""></iframe></div>
  </section>

  <section data-type="sect1" id="la-segunda-diferencia-vLNdfno">
    <h1>La segunda diferencia</h1>
    <h2>La semiótica de la información</h2>

    <p class="text-p">
      Como estrategia metodológica de análisis, estudiar la información simplementene en términos matemáticos y técnicos puede resultar incompleto. Aunque en términos de ingeniería es eficiente su formalización, como objeto cultural necesita de otros rasgos significativos importantes. De acuerdo con Dalhgren, en <i>Meaning and/vs. Information in Media Studies</i>, un estudio de la comunicación basado en la información, en este sentido de la primera diferencia, "tiende a ignorar los contextos discursivos y las dimensiones textuales que pueden impactar el sentido de los mensajes, y por lo tanto promueven una visión reductivista de la información" <span data-type="footnote"><a href="#fn25">25</a></span>. Igualmente, para Yoshimi, la "'información' necesariamente implica la creación de significado. No obstante, bajo la creciente influencia de la teoría de la información de Shannon, este aspecto inherente de la creación de significado se ha perdido" <span data-type="footnote"><a href="#fn26">26</a></span>. Como veremos, el significado es precisamente un elemento esencial para el concepto de información, pues, aunque un sustrato físico sea manipulado para contener diferencias, no cobra sentido hasta que de allí se produzca una interpretación. Es, además, esencial para una aproximación humanista de la información, pues un humanista no puede trabajar de la misma manera que un ingeniero de la información; su propósito no está en solo registrar diferencias de la manera más eficiente posible, sino en darles un sentido, una escala humana y un lugar dentro de la historia de la cultura. Así, un humanista no puede asentarse cómodamente en los terrenos de la primera diferencia. Como lo afirmaría el antropólogo Cliford Geertz, el estudio de la cultura requiere descripciones densas —<i>thick descriptions</i>— <span data-type="footnote"><a href="#fn27">27</a></span> que no asuman la complejidad de lo humano de forma superficial ni incompleta, sino que ofrezcan interpretaciones que den cuenta del entramado semiótico y la narrativa que fluye en las interacciones humanas, y aquí agregaríamos que para un nuevo humanismo se deberían integrar también las interacciones no-humanas.
    </p>

    <p class="text-p">
      Si recordamos, la segunda diferencia que propone Bateson en su definición de información consiste en <mark>hacer</mark> una diferencia. En otras palabras, en actuar a partir de un nuevo conocimiento, o en responder activamente frente a un registro de la primera diferencia, si se quiere. Como lo vería MacKay <span data-type="footnote"><a href="#fn28">28</a></span>, en contraste con la teoría matemática de la información, que es mucho más técnica y formal, la segunda diferencia es la idea de información que tenemos en mente cotidianamente, la idea intuitiva y común. Ganamos nuevo conocimiento cuando leemos las noticias, cuando alguien nos cuenta algo, cuando aprendemos luego de una experiencia, cuando sabemos algo nuevo. Además, nuestro cuerpo también contiene información, también es un sustrato que queda marcado con la experiencia. Es así como un mensaje es más significativo que un agregado abstracto de bits porque tiene una implicación pragmática. De esta manera, hacer una diferencia es aplicar un conocimiento para efectuar un hecho en el mundo, y así causar que el mundo sea diferente. Es en este sentido, justamente, que el Filosofo Ludwig Wittgenstein decía en su libro Investigaciones filosóficas que el "uso es el significado" <span data-type="footnote"><a href="#fn29">29</a></span>, pues es el punto en el que lo semántico y lo pragmático desdibujan sus bordes. Es decir, el punto en el que el reconocimiento de las categorías que nos indican las diferencias tienen un valor y un efecto en el mundo; la equivalencia entre un signo y su referencia y el concreto uso de esa referencia desaparece en la acción concreta de las personas y otros seres vivos. 
    </p>

    <p class="text-p">
      En cuanto a los estudios de la comunicación, Dalhgren afirma que considerar el significado despliega nuevas concepciones acerca de la información: "ya que la noción de lo que realmente aparece en las cabezas de las personas no es necesariamente idéntica con la intención de los remitentes o los contenidos de los mensajes, uno abre la puerta a la reflexión acerca de lo que las audiencias "hacen" de los mensajes" <span data-type="footnote"><a href="#fn30">30</a></span>. Este es un señalamiento esencial, porque nos permite pensar en un nuevo problema de la información: un mensaje —o un signo, si quisiéramos usar un término semiótico— no contiene el significado; el sentido no está en las letras de una palabra, sino en la mente y en las acciones de quien las lee. Para hacer más evidente la idea pensemos en un ejemplo: supongamos que vamos por un callejón oscuro y alguien grita “¡cuidado con el perro!”. En este caso, una acción sensata sería, por supuesto, salir corriendo, o tal vez esconderse, porque el signo "perro" en este caso puede relacionarse con la noción del peligro. Para Wittgenstein, tanto ese pensamiento acerca del peligro como la acción subsecuente de salir corriendo son el significado de la palabra "perro" en ese contexto particular. Por el perro, debo tener cuidado conmigo mismo. La relación semántica de peligro lleva consigo la acción pragmática de escapar. Pero en otro caso, digamos uno en el que llevamos a una mascota al veterinario, exactamente la misma expresión puede tener otro sentido: "¡cuidado con el perro!" se relaciona con la fragilidad de un animal, y con que debemos tratarlo de buena manera. El perro pasa de ser una amenaza a algo que se encuentra amenazado. La semántica y la pragmática son totalmente diferentes en ese nuevo contexto. Así, y esta es una idea esencial para el argumento de este ensayo, el mismo signo o mensaje puede tener sentidos diferentes dependiendo de las circunstancias, los propósitos y las capacidades de quien interpreta. En otras palabras, no basta con registrar el mensaje en un sustrato, porque el mismo signo puede intepretarse de muchas maneras diferentes; es solo en la acción concreta de un agente que la información en el signo se completa. Esta idea aplica para cualquier tipo de representación informacional, sea la palabra "perro", en español, o un sistema codificado en binario que a su vez es presentado en una interfaz computacional. Volviendo a la idea en la que hemos insistido, aunque los aspectos técnicos de la información son muy importantes, no puede dejarse de lado el significado. Aunque las humanidades tradicionales —por ejemplo, como las concebía el historiador de arte Ernst Gombrich—asumían que es el texto en su sentido amplio el que contiene el significado, y que el propósito del académico consistía entonces en decifrarlo, este problema nos hace ver que no es así, que descifrar es poner de sí mismo. Toda lectura es un acto subjetivo, aunque no por eso indeterminado o completamente diferente al de los demás sujetos que podrían interpretar el mismo signo. Interpretar quiere decir participar, o, como lo vería Wittgenstein, ser parte de unos juegos del lenguaje —y aquí lenguaje se refiere a cualquier forma de comunicación, no solo al habla o a la escritura—. De este modo, cuestionar la información requiere también cuestionar la tradición de las humanidades: no existen sentidos orginales ocultos en los registros informacionales de la cultura humana, pues esos registros solo cobran sentido para quienes los interpretan. Entender lo digital de forma humana nos obliga a pensar necesariamente en la subjetividad que participa, en quien está al otro lado de la pantalla, o quien pone sus ojos en el libro.
    </p>

    <div class="p5-wrapper"><p>test camino de emojis</p><iframe src="https://srsergiorodriguez.github.io/exploraciones-sketches/C1/5interp/" width="650px" height="450px" frameborder="0" allowfullscreen=""></iframe></div>

    <h2>El camino de interpretantes</h2>

    <p class="text-p">
      La semiótica, que a diferencia de la teoría matemática de la información se preocupa más que todo por el significado, tiene mucho más que decir, y qué discutir, acerca de esta concepción de la información. Por ejemplo, para Eco <span data-type="footnote"><a href="#fn31">31</a></span>, el significado es una especie de lugar al que se llega luego de seguir varios caminos y bifurcaciones de sentido guiadas por un código, es decir, usando la terminología semiótica, es un resultado que lleva de un signo a un interpretante último a través de una secuencia de interpretantes y finalmente a la obtención de un objeto. En otras palabras, interpretar es una elaboración que puede relacionar varias respuestas encadenadas que llevan a un significado final para la situación particular en la que se encuentra quien interpreta. Pensemos en cómo llegamos a adivinar —o no— las secuencias de emojis en el ejemplo anterior, tuvimos que elaborar nuestra interpretación a través de una serie de asociaciones —de interpretantes— que nos iban llevando de un objeto a otro hasta que decantaron en un sentido final. Esas asociaciones estaban marcadas por conocimientos personales previos y por un propósito: encontrar dichos populares; si nuestros conocimientos o propósitos fueran diferentes, el sentido de los emojis tomaría caminos diferentes. 
    </p>

    <div class="p5-wrapper"><p>test camino de emojis</p><iframe src="https://srsergiorodriguez.github.io/exploraciones-sketches/C1/5interp/" width="650px" height="450px" frameborder="0" allowfullscreen=""></iframe></div>

    <p class="text-p">
      Anclemos esta imagen del camino de interpretantes al argumento general. Kockelman <span data-type="footnote"><a href="#fn32">32</a></span> afirma que las ideas de Donald MacKay mencionadas antes ya fueron pensadas por el filósofo Charles Sanders Peirce mucho tiempo atrás, a principios del siglo XX. Esto nos permitirá ver que es posible considerar al significado dentro de la gran concepción de la información, y darle el lugar concreto que merece. Peirce, sin que siquiera se asomara en el panorama la invención de los computadores digitales, concebía la información de dos maneras diferentes:
    </p>

    <p class="text-p">
      Por una parte, y de forma análoga a la relación entre los tipos de contenido-informacional, Peirce entendía que la cantidad de información estaba dada por el producto, o sea, la multiplicación, entre lo que él llamaba amplitud lógica y profundidad lógica. O lo que en semiótica llaman denotación —el conjunto de cosas que caben dentro de una misma categoría— y connotación —las cualidades que tienen las cosas que están dentro de la misma categoría—. La denotación determina la amplitud lógica y la connotación la profundidad lógica. Para hacer esto más claro pensemos en un ejemplo: si volvemos a tratar de codificar las letras del español, podríamos decir que cualquier letra —de la A a la Z— denota a la categoría de las letras en general. Ahora veamos un caso de letra, la letra Q. Las condiciones de la letra Q —tener una forma particular y ser mayúscula— son sus connotaciones. Por eso, la letra f, que tiene otra forma y es minúscula tiene otras connotaciones, a pesar de que ambas denotan la categoría de las letras. Si descubriéramos que existe una nueva letra, además de las 27 que ya conocemos, se ampliaría la amplitud lógica y la denotación, y si descubriéramos que, además de tener formas particulares y de estar en mayúsculas o minúsculas, las letras también tienen, digamos, color, entonces se ampliaría la profundidad lógica y la connotación. Para Peirce, tanto la denotación como la connotación aumentan la cantidad de información, así que en este sentido estamos hablando de un sistema de medida más vago pero equivalente a la teoría matemática de la información. Más connotación o más denotación produce más información. Aunque Peirce no planteó una unidad de medición como el bit, su idea apuntaba a que, en principio, la información es técnicamente medible en cuanto a su representación, y esta medición se debe a su relación con las categorías que diferencia y a la cantidad de detalle que brinda. En este sentido, las apreciaciones acerca del tipado lógico y de la economía de la información todavía aplican. 
    </p>

    <div class="p5-wrapper"><p>Denotación y connotación (una serie de elementos que entran en la misma categoría, una historia densa)</p><iframe src="https://srsergiorodriguez.github.io/exploraciones-sketches/C1/5interp/" width="650px" height="450px" frameborder="0" allowfullscreen=""></iframe></div>

    <p class="text-p">
      Por otra parte, Peirce también entendía la información como la relación entre un tópico y un foco en la construcción de un un razonamiento —reason, en inglés— a través de declaraciones —utterances, en inglés—. Esta segunda manera de entender guarda mayor relación con nuestra concepción cotidiana de la información. Primero, el tópico es lo que ya se conoce y se da por sentado cuando se recibe la declaración, la frase comunicativa con la que se quiere expresar algo. Pensemos que un callejón oscuro nos lanzan la expresión: “¡cuidado con el perro!”. Si lo leemos a la luz de lo dicho antes, el tópico es la información que ya se tiene almacenada, o incluso la historia biográfica que se lleva como un bagaje interpretativo. En este caso, es nuestro conocimiento acerca de lo que hacen los perros. Segundo, el foco es la parte de la declaración que da nueva información, que da una nueva forma, y por lo tanto que informa. En este caso, la palabra “cuidado” nos está informando sobre algo nuevo que no conocíamos, que el perro, probablemente, nos va a morder. Tercero, la razón es el argumento lógico al que apuntan la relación entre el tópico y el foco. El argumento en el ejemplo sería: “debería correr”. Así, esta idea complementa la noción semántica del significado propuesta por Eco mencionada antes, es decir, el camino de interpretantes, y la idea cotidiana de información como la concebía MacKay; pero también establece un sistema formal para entender la manera en la que, para la semiótica Peirceana, se conoce el mundo para poder actuar en él. Como lo entendería Peirce, el proceso de crear argumentos mentales pasando de focos a tópicos establece un sistema de creencias en quien sigue el argumento, y las creencias son siempre una disposición para actuar en un estado futuro. Así, podemos imaginar que esta concepción de la información se adecúa a la segunda diferencia, a la información como la creación de disposiciones para actuar.
    </p>

    <p class="text-p">
     El concepto de libertad semiótica propuesto por el biólogo y semiótico Jesper Hoffmeyer <span data-type="footnote"><a href="#fn33">33</a></span> nos permite ampliar las ideas Peirceanas que acabamos de describir. Para Hoffmeyer, la libertad semiótica consiste en la capacidad que tienen los organismos vivos para crear nuevos sentidos a partir de los constreñimientos que la evolución y sus experiencias previas han definido sobre ellos. Al fin y al cabo, en su etimología, información proviene del Latín informare que quiere decir algo así como "dar forma" o "darse forma". En otras palabras, la libertad semiótica está dada por el tópico, el bagaje informacional previo con el que ya contamos, la forma que ya tenemos que nos permite crear nuevos argumentos cuando ante nosotros se presenta en un nuevo foco que nos permitirá formarnos de nuevo. La ventaja que tiene la conceptualización de Hoffmeyer es que nos permite escapar de la terminología puramente lingüística y lógica y nos permite ver que la información, en este sentido, no depende solamente de mensajes escritos sino de un entramado que involucra al cuerpo, a las emociones, al instinto y también al lenguaje. Además, el pensamiento biológico de Hoffmeyer permite extender el concepto de información a cualquier ser vivo. Pensemos primero, por ejemplo, en el habla humana. Las condiciones particulares de nuestro aparato fonador y nuestros oídos nos dan cierta libertad semiótica que nos permite comunicarnos dentro de un sistema de signos particular; nos dan cierta forma con la que podemos informarnos. Por el contrario, las polillas geométridas nocturnas solo pueden percibir cierta frecuencia de sonidos en la que se encuentra el rango sonoro de su mayor depredador, el murciélago cazador. Así, a pesar de las limitaciones, el oído de las polillas les permite la libertad semiótica de identificar peligros relevantes para su entorno y actuar acertadamente en la mayoría de las ocasiones; también se informan desde sus posibilidades. Así, paradójicamente, para Hoffmeyer las limitaciones ofrecen libertad para actuar desde las particularidades subjetivas. En el sentido Peirceano, el tópico define con qué libertad interpretaremos el foco, y así define un bagaje previo que dará forma al camino de interpretantes. En el sentido Hoffmeyeriano, el andamiaje biológico constituido por nuestra historia evolutiva y por nuestras experiencias previas crea información que nos permite hacer una diferencia cuando actuamos. La historia biológica configura también una tautología, un lugar de enunciación. El camino de interpretantes de una situación particular se integra al camino de interpretantes de una vida completa, o incluso al camino de interpretantes de la historia evolutiva de una especie. 
    </p>

    <h2>La cirulación semiótica de la información</h2>

    <p class="text-p">
      La referencia biológica previa, y la alusión a las diferencias entre los cuerpos de los animales abre la puerta a una visión más amplia del concepto de información y sus connotaciones pragmáticas. Recordemos que aquí estamos defendiendo, con Wittgenstein, que el uso es el significado. Para Bateson y para los biosemióticos contemporáneos que en parte se han inspirado en él, el significado es la adaptación de los organismos vivientes al entorno en el que viven, y la acción subsiguiente sobre tal entorno. Esa es la idea general que está implícita en la parte de la frase Batesoniana que habla de “hacer una diferencia”. Desde esta mirada, el significado está estrechamente ligado a estar vivo, porque significar es crear una serie de distinciones del mundo, de diferencias adaptativas, que permiten actuar y mantenerse con vida a través del ajuste de las retroalimentaciones que ofrece el entorno, y así seguir estableciendo aún más diferencias y por lo tanto más vida. Francisco Varela y Humberto Maturana en El árbol del conocimiento afirman que "vivir es conocer (vivir es acción efectiva en el existir como ser vivo)" <span data-type="footnote"><a href="#fn34">34</a></span>.
    </p>

    <p class="text-p">
      Dicho lo anterior, podemos hacer una nueva distinción frente a los computadores digitales, los contenedores por excelencia del metamedio informacional binario. Manuel Castells <span data-type="footnote"><a href="#fn35">35</a></span> advierte que no debemos confundir tener información con saber —o con conocer, si queremos seguir los términos que hemos usado—. De acuerdo con la idea a la que hemos venido dando forma, la información en relación con la utilidad pragmática no implica solo crear un registro de datos que se guardan pasivamente y que nunca son consultados. Por el contrario, como lo entendería MacKay <span data-type="footnote"><a href="#fn36">36</a></span>, la información construye determinada predisposición para actuar. Así, tanto MacKay, el estricto teórico de la información, como los biosemióticos cuyo interés reside en encontrar las formas en las que el sentido y la vida coemergen coinciden entonces en que significar es crear una disposición para actuar, o un sistema útil de valoración de la experiencia.
    </p>

    <p class="text-p">
      Si seguimos con la idea de los biosemióticos, un computador digital registra, almacena y manipula muy eficientemente el contenido informacional con el lenguaje universalista de la información formalizada, pero, debido a que no vive, no tiene propósitos propios y por lo tanto es incapaz de dar significado al mundo. Incluso los sistemas de inteligencia artificial más sofisticados del presente no pueden interpretar, porque no pueden crear sentido útil para ellos mismos; su existencia es meramente maquinal, a pesar de que sus procesos estadísticos subyacentes en ocasiones nos hagan pensar que su comportamiento es similar al de un ser vivo. En otros términos, un computador no <mark>hace</mark> una diferencia, pues siempre necesita de un ser humano —u otro ser vivo, si es el caso— para que finalmente haga algo con la información manipulada, para que complete el ciclo Batesoniano. Así, reuniendo algunas cosas dichas antes, no podemos confiarnos en que lo digital resuelva todos los problemas de la comunicación y la interpretación humana: hay características no codificables del mundo y para significar la información hay que estar con vida, porque es la única forma de encontrar valor en el registro del substrato.
    </p>

    <p class="text-p">
      Shunya Yoshimi dice que la información "involucra encontrar patrones o leer mensajes en los objetos de la observación (sean fenómenos naturales o sociales). Tales 'patrones' o 'mensajes' no son reducibles a meros datos. Son educidos recursivamente por observación de las formas de vida que seleccionan patrones de su entorno. La 'información', por lo tanto, no puede ser reducida a unidades de bits. El concepto de 'información' tiene sus bases en los procesos de vida donde la diferencia es descubierta en el entorno" <span data-type="footnote"><a href="#fn37">37</a></span>. A esta dinámica, Bateson justamente la denominaba "el patrón que conecta", es decir, el sistema de acomplamiento formal entre un organismo y su ambiente. Un organismo conforma un patrón corporal y de acción que se adapta a las condiciones del entorno en el que vive. Así, la información no es solo una interpretación pasiva sino una forma de encajar con el entorno. La predisposción para actuar y el conocer conforman un sistema de valoración del mundo. Las tautologías batesonianas conforman sistemas de entendimiento que tienen patrones relevantes para el mundo en el que se habita. En otras palabras, los agentes dan al sustrato en el que consigan la información su propia forma, o una forma que encaja con ellos mismos. Aunque el computador sea un metamedio, es un metamedio que imita cosas que son percibibles para nuestra configuración corporal humana: pantallas para los ojos, teclados para los dedos, sonidos para los oídos. No existen computadores con sonar, porque no somos murciélagos. Sin embargo, ¿tienen los murciélagos información? Si anteriormente afirmábamos que el sustrato de la información ejerce torsión sobre las vidas de los humanos, ahora podemos afirmar que, recíprocamente, los medios tienen forma humana, o que en cierto sentido los humanos informan a los medios. De tal manera, una lectura humanística de la información necesariamente implica pensar en la co-ocurrencia de la información, en la manera como el medio y el intérprete cambian de forma conjuntamente.
    </p>

    <p class="text-p">
     Adicionalmente, lo dicho antes nos lleva a una conexión con el modo de pensamiento que reciente y contradictoriamente se ha venido a llamar <i>posthumanidades</i> <span data-type="footnote"><a href="#fn38">38</a></span>. Es decir, al menos desde una acepción cibernética afín a los argumentos de este ensayo, la concepción de que las humanidades deben llegar a un punto en el que para entender lo humano también requieren entender lo no-humano: las cosas y los otros seres vivientes. El modelo en el que los signos pasivamente son interpretados por los humanos, el antropocentrismo semiótico, debe reemplazarse por la concepción relacional de que todos los seres vivos interpretan y dan sentido. Si ya afirmamos que el sentido cambia de acuerdo al contexto y al propósito, podemos llevar esta idea más lejos y afirmar que el sentido cambia de acuerdo a la subjetividad que interpreta. La información, más que un proceso de codificación y decodificación de mensajes, y del desciframiento de un sentido concreto, está dada por la dinámica de relacionamiento entre subjetividades —humanas o no—. El semiólogo Yuri Lotman afirmaba que además de una atmósfera, que regula las condiciones de vida de los organismos, existe una semiósfera, que regula la comunicación y el mantenimiento de la información necesaria para la vida <span data-type="footnote"><a href="#fn39">39</a></span>. Las humanidades, que necesitan descentrar al humano, deben añadir a sus descripciones densas una forma de pensamiento ecológico que involucre a otras formas de significación, que se informan y que dan forma a los sustratos informacionales que se intercambian en la complejidad relacional de la actividad social y biológica. En otras palabras, las humanidades deben estudiar y a la vez ubicarse dentro de la semiósfera. Este cambio de pensamiento es especialmente importante para una aproximación a las humanidades digitales en Latinoamérica que, recordemos, se encuentra en las márgenes de la gran narrativa humanística y del desarrollo infraestructural y tecnológico de lo digital. Las humanidades tradicionales han concebido a grupos subordinados no como seres significantes sino solo como objetos de estudio, como objetos para la observación exotizante, o como ejemplos de lo contrario a lo humano: lo bárbaro. La estructura tradicional de las humanidades occidentales, las así llamadas artes liberales, tienen su nombre porque estaban pensadas para las personas libres, los ciudadanos que tenían capacidad para tomar decisiones en la asamblea pública, en contraposición a quienes no podían cultivarse ni forjar opiniones ciudadanas. Descentrar lo humano, desde una perspectiva poshumanista, apoyada por una reflexión crítica de los fundamentos de lo digital, como lo hicimos en este caso con respecto al concepto de información, permite darle un lugar a la pregunta acerca de cómo distintas subjetividades, incluyendo a los grupos subordinados, se informan; como es el caso de Latinoamérica, y otros lugares del sur global. Así, tal vez para hacerla más críptica, podríamos añadir a la definición de Bateson que la información es una diferencia que hace una diferencia entre seres diferentes. 
    </p>
    
    <div class="p5-wrapper"><p>test camino de emojis</p><iframe src="https://srsergiorodriguez.github.io/exploraciones-sketches/C1/5interp/" width="650px" height="450px" frameborder="0" allowfullscreen=""></iframe></div>
  </section>

  <section data-type="sect1" id="conclusiones-DLYwf7o">
    <h1>Conclusiones</h1>

    <p class="text-p">
      En este recorrido usamos como excusa la frase Batesoniana que afirma que la información es una diferencia que hace una diferencia para establecer una lectura densa del concepto de información. Así pudimos ver que, aunque se pueden separar artificialmente, existe una estrecha correlación entre los aspectos técnicos de la representación de la información —la medida de diferencias en bits, los tipos de contenido-informacional, la intención universalista del binario, etc.— con los aspectos significativos de la información —la acción efectiva, los hábitos y la disposición para actuar, la necesidad de que la información representada sea interpretada para que realmente haga una diferencia, el interrelacionamiento informacional de la semiósfera—. Tanto los aspectos técnicos como los aspectos semióticos de la información son esenciales para entender las posiblidades y las limitaciones de lo computacional, pues permiten, por una parte, ver cómo lo digital se construye a partir de la presunción de un lenguaje universalizante, pero también cómo ese lenguaje debe finalmente ser interpretado y enactuado por una subjetividad concreta. Para los humanistas especialmente, quienes trabajamos con interpretaciones de la cultura, es fundamental no perder de vista que la simple manipulación de información formalizada no es suficiente para hacer una diferencia; siempre se requiere que esa manipulación tenga un efecto para alguien en un momento particular. Las humanidades, que ya se encuentran cómodas en los aspectos interpretativos, pueden ganar mucho si se aproximan también con confianza y fundamentos a los aspectos técnicos y técnológicos de los medios contemporáneos. Adicionalmente, discutimos las limitaciones que plantean las teorías formalistas de la información: el ocultamiento de las cualidades no codificables de un objeto o un fenómeno. Desde las humanidades, y a partir de esta limitante, es necesario hacerse constantemente la pregunta de qué es lo que no se está representando, qué se dejó de lado, qué otras dimensiones se podrían introducir. Sin embargo, esto no es una condición única de lo digital, pues los conceptos de contenido-informacional son suficientemente amplios para cubrir otras formas de representación. Por ejemplo, los libros pueden medirse también en cuanto a su contenido informacional y, analíticamente, es posible determinar qué tanta información contienen y qué dimensiones abarca su contenido. Así, entender el concepto de información no solo es útil para dar cuenta de lo digital sino para cualquier forma de comunicación discreta. En este sentido el conocimiento de lo digital informa también otros lugares relevantes para los humanistas. Según afirmamos, el medio y el sujeto se informan conjuntamente.
    </p>

    <p class="text-p">
      La información es un bloque fundamental para otros conceptos digitales: el código, las funciones, los algoritmos, las estructuras de datos, etc. Aunque cada uno de estos conceptos introduce nuevas capas de abstracción, todo se reduce a un agregado manipulable de unos y ceros, al menos en términos computacionales. Conocer los fundamentos nos permite hacer más transparente la arquitectura de la computación y nos facilita aproximarnos a ella de formas críticas y creativas. Así, como vimos, se hace evidente que, aunque el concepto de información no es perfecto, ha tenido una efectividad extendida en las sociedades contemporáneas a pesar de varias dificultades concretas. Una lectura concienzuda de la información desde las humanidades puede ayudar a superar las barreras del significado y a tener un concepto de información más abarcante.
    </p>

    <p class="text-p">
      Finalmente, hablamos del interrelacionamiento del significado y la circulación de la información. Esta reflexión trajo consigo una propuesta particular para las aproximaciones desde Latinoamérica tanto a lo humanístico como a lo digital: descentrar al humano en lo humanístico y entender que la información circula en una semiósfera diversa permite reconocer el lugar propio, la localidad y la economía de la información y romper la distinción binaria que establece al humanismo como la alternativa a la barbarie.
    </p>
  </section>

  ---
</section>

        <h1>Referencias</h1>
        <ol data-type="footnotes">
    <li id="fn1">Gregory Bateson, Mind and Nature: A Necessary Unity (New York: Dutton, 1979), 99.</li>
    <li id="fn2">Claude E. Shannon y Warren Weaver, The Mathematical Theory of Communication (Urbana: University of Illinois Press, 1975).</li>
    <li id="fn3">Nicholas Gane y David Beer, New Media. the Key Concepts, English ed, The key concepts, 1747-6550 (Oxford ; New York: Berg, 2008).</li>
    <li id="fn4">Paul Kockelman, «Information Is the Enclosure of Meaning: Cybernetics, Semiotics, and Alternative Theories of Information», Language &amp; Communication 33, n.o 2 (abril de 2013): 115-27, https://doi.org/10.1016/j.langcom.2013.01.002.</li>
    <li id="fn5">Paul Kockelman, The art of interpretation in the age of computation (New York, NY: Oxford University Press, 2017), 7.</li>
    <li id="fn6">Geoffrey C. Bowker y Susan Leigh Star, Sorting Things out: Classification and Its Consequences, First paperback edition, Inside Technology (Cambridge, Massachusetts London, England: The MIT Press, 2000), 16.</li>
    <li id="fn7">Alan Kay y Adele Goldberg, «Personal Dynamic Media», en The New Media Reader, ed. Noah Wardrip-Fruin y Nick Montfort (Cambridge, Mass: MIT Press, 2003), 391-404.</li>
    <li id="fn8">Lev Manovich, Software Takes Command: Extending the Language of New Media, International Texts in Critical Media Aesthetics (New York; London: Bloomsbury, 2013).</li>
    <li id="fn9">Friedrich A. Kittler, Gramophone, Film, Typewriter, Writing Science (Stanford, Calif: Stanford University Press, 1999), 1.</li>
    <li id="fn10">Umberto Eco, The Search for the Perfect Language, trad. James Fentress (Oxford: Blackwell Publishers, 1995).</li>
    <li id="fn11">Umberto Eco, La estructura ausente, trad. Francisco Serra Cantarell (Barcelona: Debolsillo, 2011).</li>
    <li id="fn12">Kittler, Gramophone, Film, Typewriter.</li>
    <li id="fn13">Kittler, 18.</li>
    <li id="fn14">John Seely Brown y Paul Duguid, The social life of information, Updated, with a new preface (Boston, Massachusetts: Harvard Business Review Press, 2017).</li>
    <li id="fn15">Bowker y Star, Sorting Things Out.</li>
    <li id="fn16">Bowker y Star, 28.</li>
    <li id="fn17">Yanni A. Loukissas, All data are local: thinking critically in a data-driven society (Cambridge, Massachusetts: The MIT Press, 2019).</li>
    <li id="fn18">Donald MacCrimmon MacKay, Information, mechanism and meaning (Cambridge: M.I.T. Press, 1969).</li>
    <li id="fn19">Kockelman, The art of interpretation in the age of computation; Kockelman, «Information Is the Enclosure of Meaning».</li>
    <li id="fn20">Bateson, Mind and Nature.</li>
    <li id="fn21">Siegfried Zielinski, Arqueología de los Medios: Hacia el Tiempo Profundo de la Visión y la Audición Técnica (Bogotá: Ediciones Uniandes, 2012).</li>
    <li id="fn22">Jussi Parikka, A geology of media, Electronic mediations, volume 46 (Minneapolis ; London: University of Minnesota Press, 2015).</li>
    <li id="fn23">Domenico Fiormonte, «Lenguas, códigos, representación. Márgenes de las Humanidades Digitales», en Humanidades digitales, ed. Isabel Galina Russell et al. (Ciudad de México: Bonilla Artigas Editores / Red de Humanidades Digitales, 2018), 39-81.</li>
    <li id="fn24">Kockelman, The art of interpretation in the age of computation.</li>
    <li id="fn25">Peter Dahlgren, «Meaning and/vs. Information in Media Studies», Loisir et Société / Society and Leisure 21, n.o 1 (enero de 1998): 44, https://doi.org/10.1080/07053436.1998.10715562.</li>
    <li id="fn26">Shunya Yoshimi, «Information», Theory, Culture &amp; Society 23, n.o 2-3 (mayo de 2006): 271, https://doi.org/10.1177/0263276406062682.</li>
    <li id="fn27">Clifford Geertz, The Interpretation of Cultures: Selected Essays, 3rd edition, Basic Book-s (New York: Basic Books, 2017).</li>
    <li id="fn28">MacKay, Information, mechanism and meaning.</li>
    <li id="fn29">Ludwig Wittgenstein y G. E. M. Anscombe, Philosophische Untersuchungen =: Philosophical investigations, trad. P. M. S. Hacker y Joachim Schulte, Rev. 4th ed (Chichester, West Sussex, U.K. ; Malden, MA: Wiley-Blackwell, 2009), 25e.</li>
    <li id="fn30">Dahlgren, «Meaning and/vs. Information in Media Studies», 49.</li>
    <li id="fn31">Eco, La estructura ausente.</li>
    <li id="fn32">Kockelman, «Information Is the Enclosure of Meaning».</li>
    <li id="fn33">Jesper Hoffmeyer, Signs of Meaning in the Universe (Bloomington, Ind.: Indiana Univ. Press, 1998).</li>
    <li id="fn34">Humberto Maturana R. y Francisco J. ( Varela, El árbol del conocimiento: las bases biológicas del conocimiento humano (Buenos Aires: Lumen, 2003), 116.</li>
    <li id="fn35">Manuel Castells, The rise of the network society, The information age : economy, society, and culture, v. 1 (Chichester, West Sussex ; Malden, MA: Wiley-Blackwell, 2010).</li>
    <li id="fn36">MacKay, Information, mechanism and meaning.</li>
    <li id="fn37">Yoshimi, «Information», 271.</li>
    <li id="fn38">Cary Wolfe, What is posthumanism?, Posthumanities series, v. 8 (Minneapolis: University of Minnesota Press, 2010).</li>
    <li id="fn39">Juri Lotman, «On the semiosphere», Sign Systems Studies 33, n.o 1 (2005): 205-29.</li>
</ol>

      </article>
      <aside class="sidebar">
      </aside>
    </section>
  

</body></html>